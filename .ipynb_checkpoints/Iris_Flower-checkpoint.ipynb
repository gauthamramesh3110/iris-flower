{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING\n",
    "def process_data(dataset):\n",
    "    m = np.shape(dataset)[0]\n",
    "    x = np.shape(dataset)[1]\n",
    "    \n",
    "    X = dataset.values[: , 1:x-1]\n",
    "    y = dataset.values[: , x-1:x]\n",
    "    \n",
    "    n_y = np.unique(y).shape[0]\n",
    "    n_x = np.shape(X)[1]\n",
    "    \n",
    "    Y = np.zeros((m, n_y))\n",
    "    \n",
    "    for i in range(np.shape(Y)[0]):\n",
    "        if y[i]=='Iris-setosa':\n",
    "            Y[i] = np.array([1, 0, 0])\n",
    "        elif y[i]=='Iris-versicolor':\n",
    "            Y[i] = np.array([0, 1, 0])\n",
    "        elif y[i]=='Iris-virginica':\n",
    "            Y[i] = np.array([0, 0, 1])\n",
    "            \n",
    "    X = X.astype('float64')\n",
    "    Y = Y.astype('float64')\n",
    "    \n",
    "    X = X.T \n",
    "    Y = Y.T\n",
    "    \n",
    "    return X, Y, m, n_x, n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparams(n_x, n_y):\n",
    "    layer_dims = [n_x, 20, n_y]\n",
    "    learning_rate = 0.01\n",
    "    iteration = 20000\n",
    "    \n",
    "    return layer_dims, learning_rate, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACTIVATION FUNCTION\n",
    "\n",
    "def sigmoid(z):\n",
    "    x = 1.0/(1.0 + np.exp(-z))\n",
    "    return x\n",
    "\n",
    "def relu(z):\n",
    "    x = np.maximum(0, z)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALIZE WEIGHTS\n",
    "def initialize_weights(layer_dims):\n",
    "    L = np.shape(layer_dims)[0]\n",
    "    weights = {}\n",
    "    np.random.seed(3)\n",
    "    for l in range(L-1):\n",
    "        W = np.random.randn(layer_dims[l+1], layer_dims[l]) * 0.01\n",
    "        b = np.zeros((layer_dims[l+1], 1))\n",
    "        weights['W' + str(l+1)] = W\n",
    "        weights['b' + str(l+1)] = b\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORWARD PROPAGATION\n",
    "def forward_propagation(X, layer_dims, weights):\n",
    "    L = np.shape(layer_dims)[0]\n",
    "    \n",
    "    cache = {}\n",
    "    A_prev = X\n",
    "    cache['A0'] = X\n",
    "        \n",
    "    for l in range(L-1):\n",
    "        W = weights['W' + str(l+1)]\n",
    "        b = weights['b' + str(l+1)]\n",
    "        \n",
    "        Z = np.dot(W, A_prev) + b\n",
    "        A = np.zeros(np.shape(Z))\n",
    "        \n",
    "        if(l == L-2):\n",
    "            A = sigmoid(Z)\n",
    "        else:\n",
    "            A = relu(Z)\n",
    "        \n",
    "        cache['Z' + str(l+1)] = Z\n",
    "        cache['A' + str(l+1)] = A\n",
    "        \n",
    "        A_prev = A\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COST FUNCTION\n",
    "\n",
    "def cost(AL, Y, m):\n",
    "    x = (-1/m) * np.sum( (Y) * np.log(AL) + (1-Y) * np.log(1-AL) )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKPROPAGATION\n",
    "def backward_propagation(Y, cache, weights, layer_dims, m):\n",
    "    L = np.shape(layer_dims)[0]\n",
    "    \n",
    "    A = cache['A' + str(L-1)]\n",
    "    dA = - (np.divide(Y, A) - np.divide(1 - Y, 1 - A)) \n",
    "    \n",
    "    gradients = {}\n",
    "    \n",
    "    for l in  reversed(range(L-1)):\n",
    "        W = weights['W' + str(l+1)]\n",
    "        A_prev = cache['A' + str(l)]\n",
    "        Z = cache['Z' + str(l+1)]\n",
    "        dZ = np.zeros(np.shape(Z))\n",
    "        if l == L-2:\n",
    "            dZ = dA * sigmoid(Z) * (1 - sigmoid(Z))\n",
    "        else:\n",
    "            dZ = dA * 1 * (Z >= 0)\n",
    "            #dZ = dA * sigmoid(Z) * (1 - sigmoid(Z))\n",
    "        \n",
    "        dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "        db = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        \n",
    "        dA = np.dot(W.T, dZ)\n",
    "        \n",
    "        gradients['dW' + str(l+1)] = dW\n",
    "        gradients['db' + str(l+1)] = db\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE WEIGHTS\n",
    "\n",
    "def update_weights(weights, gradients, learning_rate, layer_dims):\n",
    "    L = np.shape(layer_dims)[0]\n",
    "    \n",
    "    #print('weights: ')\n",
    "    #print(weights['W' + str(L-1)])\n",
    "    \n",
    "    #print('gradients: ')\n",
    "    #print(gradients['dW' + str(L-1)])\n",
    "    \n",
    "    for l in range(L-1):\n",
    "        W = weights['W' + str(l+1)];\n",
    "        dW = gradients['dW' + str(l+1)]\n",
    "        b = weights['b' + str(l+1)]\n",
    "        db = gradients['db' + str(l+1)]\n",
    "        W = W - learning_rate * dW\n",
    "        b = b = learning_rate * db\n",
    "        \n",
    "        weights['W' + str(l+1)] = W\n",
    "        weights['b' + str(l+1)] = b\n",
    "    return weights\n",
    "    #print('weights: ')\n",
    "    #print(weights['W' + str(L-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEURAL NET\n",
    "\n",
    "def train_neural_network():\n",
    "    iris_train = pd.read_csv('Iris_Train_2.csv', sep=',', header=0)\n",
    "    iris_test = pd.read_csv('Iris_Test_2.csv', sep=',', header=0)\n",
    "    \n",
    "    X, Y, m, n_x, n_y = process_data(iris_train)\n",
    "    layer_dims, learning_rate, iteration = find_hyperparams(n_x, n_y)\n",
    "    L = np.shape(layer_dims)[0]\n",
    "    \n",
    "    weights = initialize_weights(layer_dims)\n",
    "    for i in range(iteration):\n",
    "        cache = forward_propagation(X, layer_dims, weights)\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            AL = cache['A' + str(L-1)]\n",
    "            print(cost(AL, Y, m))\n",
    "            print(np.shape(AL))\n",
    "            \n",
    "        gradients = backward_propagation(Y, cache, weights, layer_dims, m)\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            dA = gradients['dW' + str(L-1)]\n",
    "            print(np.shape(AL))\n",
    "            \n",
    "        weights = update_weights(weights, gradients , learning_rate, layer_dims)\n",
    "        \n",
    "    #find accuracy training\n",
    "    X, Y, m, n_x, n_y = process_data(iris_train)\n",
    "    cache = forward_propagation(X, layer_dims, weights)\n",
    "    \n",
    "    AL = cache['A' + str(L-1)];\n",
    "    output = AL\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(n_y):\n",
    "            output[j,i] = 1 * (output[j,i] == max(output[:, i]))\n",
    "    \n",
    "    loss = np.absolute(output - Y)\n",
    "    loss = np.sum(loss, axis=0)\n",
    "    success = np.count_nonzero(loss==0)\n",
    "    \n",
    "    accuracy = (success/m) * 100\n",
    "    print('training accuracy = ' + str(accuracy) + '%')\n",
    "    \n",
    "    #find accuracy test\n",
    "    X, Y, m, n_x, n_y = process_data(iris_test)\n",
    "    cache = forward_propagation(X, layer_dims, weights)\n",
    "    \n",
    "    AL = cache['A' + str(L-1)];\n",
    "    output = AL\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(n_y):\n",
    "            output[j,i] = 1 * (output[j,i] == max(output[:, i]))\n",
    "    \n",
    "    loss = np.absolute(output - Y)\n",
    "    loss = np.sum(loss, axis=0)\n",
    "    success = np.count_nonzero(loss==0)\n",
    "    \n",
    "    accuracy = (success/m) * 100\n",
    "    print('test accuracy = ' + str(accuracy) + '%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.079174904981336\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.8463524661069551\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.6809029126272595\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.4208868354031794\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.23550210510008818\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.1690323260134799\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.13920107012056263\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.12232585408512703\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.11136363008731334\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.10361149580592495\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.09781597257805694\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.09329542056688525\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.08965505129290978\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.08664912589971464\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.08411664068899238\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.0819471878891387\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.08006421854803795\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.07841185159350994\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.07694258156513639\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "0.07562487744485952\n",
      "(3, 120)\n",
      "(3, 120)\n",
      "training accuracy = 98.33333333333333%\n",
      "test accuracy = 93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "train_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
